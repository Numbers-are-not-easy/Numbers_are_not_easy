{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a52e3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U \"trl>=0.9.6\" \"transformers>=4.44\" \"datasets>=2.19\" \"accelerate>=0.33\" peft bitsandbytes einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecec122",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Imports & config\n",
    "# =========================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import time, os\n",
    "from transformers import TrainerCallback, TrainerControl\n",
    "\n",
    "\n",
    "BASE = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "# BASE = \"google/gemma-2-9b-it\"  # uncomment to switch to Gemma 2 9B IT\n",
    "\n",
    "# --- Paths (adjust to your Kaggle Dataset names) ---\n",
    "TRAIN_PATH = \"/kaggle/input/test-data/Untitled-1 (1).jsonl\"\n",
    "VAL_PATH   = \"/kaggle/input/eval-data/dev.jsonl\"\n",
    "OUT_DIR    = f\"/kaggle/working/sft-{BASE.split('/')[-1]}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\" GPU{i}:\", torch.cuda.get_device_name(i))\n",
    "print(\"Output dir:\", OUT_DIR)\n",
    "\n",
    "# =========================================\n",
    "# 2) Data loader with schema auto-detection\n",
    "# =========================================\n",
    "ISO_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(Z|[+\\-]\\d{2}:\\d{2})$\")\n",
    "\n",
    "class TimeLimitCallback(TrainerCallback):\n",
    "    def __init__(self, limit_seconds, save_dir, tokenizer=None):\n",
    "        self.limit = limit_seconds\n",
    "        self.save_dir = save_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.t0 = time.time()\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def on_step_end(self, args, state, control: TrainerControl, **kwargs):\n",
    "        elapsed = time.time() - self.t0\n",
    "        if elapsed >= self.limit:\n",
    "            tag = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            out_dir = os.path.join(self.save_dir, f\"checkpoint_timecap_{tag}\")\n",
    "            print(f\"\\n[TimeCap] {elapsed:.0f}s elapsed — saving to {out_dir} and stopping…\")\n",
    "            # 1) save a final checkpoint (adapters) + tokenizer\n",
    "            kwargs[\"model\"].save_pretrained(out_dir)\n",
    "            if self.tokenizer is not None:\n",
    "                self.tokenizer.save_pretrained(out_dir)\n",
    "            # 2) request a final eval/save, then stop\n",
    "            control.should_evaluate = True\n",
    "            control.should_save = True\n",
    "            control.should_training_stop = True\n",
    "            # optional: write a marker file\n",
    "            with open(os.path.join(out_dir, \"TIME_CAP.txt\"), \"w\") as f:\n",
    "                f.write(f\"Stopped at global_step={state.global_step}, elapsed={elapsed:.1f}s\\n\")\n",
    "            return control\n",
    "\n",
    "def is_iso_ok(s: str) -> bool:\n",
    "    s = (s or \"\").strip()\n",
    "    return bool(ISO_RE.match(s)) or s == \"ABSTAIN\" or (\"||\" in s)\n",
    "\n",
    "def load_jsonl(path):\n",
    "    return load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "\n",
    "DEFAULT_SYS = (\n",
    "    \"You are a precise time normalizer. Output ONE line in ISO-8601 with offset \"\n",
    "    \"unless policy says ABSTAIN or A||B. No prose.\"\n",
    ")\n",
    "\n",
    "def extract_prompt_and_answer(ex: dict):\n",
    "    # Helper function to safely convert values to strings\n",
    "    def safe_str(value):\n",
    "        if value is None:\n",
    "            return \"\"\n",
    "        elif isinstance(value, str):\n",
    "            return value.strip()\n",
    "        else:\n",
    "            # Handle datetime, numbers, or other objects\n",
    "            return str(value).strip()\n",
    "    \n",
    "    # E) pre-concatenated text\n",
    "    if \"text\" in ex and isinstance(ex[\"text\"], str) and \"[ASSISTANT]\\n\" in ex[\"text\"]:\n",
    "        pieces = ex[\"text\"].split(\"[ASSISTANT]\\n\", 1)\n",
    "        prompt = pieces[0] + \"[ASSISTANT]\\n\"\n",
    "        ans = pieces[1].strip().splitlines()[0].strip()\n",
    "        return prompt, ans\n",
    "\n",
    "    # A) messages + answer\n",
    "    if \"messages\" in ex and \"answer\" in ex:\n",
    "        msgs = ex[\"messages\"] or []\n",
    "        sys = next((m.get(\"content\",\"\") for m in msgs if (m.get(\"role\",\"\").lower()==\"system\")), \"\")\n",
    "        usr = \"\"\n",
    "        for m in reversed(msgs):\n",
    "            if (m.get(\"role\",\"\").lower()==\"user\"):\n",
    "                usr = m.get(\"content\",\"\"); break\n",
    "        if not sys: sys = DEFAULT_SYS\n",
    "        prompt = f\"<s>[SYSTEM]\\n{sys}\\n[/SYSTEM]\\n[USER]\\n{usr}\\n[/USER]\\n[ASSISTANT]\\n\"\n",
    "        return prompt, safe_str(ex.get(\"answer\"))\n",
    "\n",
    "    # B) prompt + answer\n",
    "    if \"prompt\" in ex and \"answer\" in ex:\n",
    "        prompt = f\"<s>[SYSTEM]\\n{DEFAULT_SYS}\\n[/SYSTEM]\\n[USER]\\n{ex['prompt']}\\n[/USER]\\n[ASSISTANT]\\n\"\n",
    "        return prompt, safe_str(ex.get(\"answer\"))\n",
    "\n",
    "    # C) input/response OR question/target\n",
    "    for in_key, out_key in [(\"input\",\"response\"), (\"question\",\"target\")]:\n",
    "        if in_key in ex and out_key in ex:\n",
    "            prompt = f\"<s>[SYSTEM]\\n{DEFAULT_SYS}\\n[/SYSTEM]\\n[USER]\\n{ex[in_key]}\\n[/USER]\\n[ASSISTANT]\\n\"\n",
    "            return prompt, safe_str(ex.get(out_key))\n",
    "\n",
    "    # D) input_text + gold (your schema)\n",
    "    if \"input_text\" in ex and \"gold\" in ex:\n",
    "        prompt = f\"<s>[SYSTEM]\\n{DEFAULT_SYS}\\n[/SYSTEM]\\n[USER]\\n{ex['input_text']}\\n[/USER]\\n[ASSISTANT]\\n\"\n",
    "        return prompt, safe_str(ex.get(\"gold\"))\n",
    "\n",
    "    raise KeyError(\"Unsupported row schema; keys present: \" + \", \".join(sorted(ex.keys())))\n",
    "\n",
    "def to_sft_text(ex):\n",
    "    prompt, ans = extract_prompt_and_answer(ex)\n",
    "    ans = ans.strip().splitlines()[0].strip()\n",
    "    return {\"text\": prompt + ans}\n",
    "\n",
    "train_raw = load_jsonl(TRAIN_PATH)\n",
    "val_raw   = load_jsonl(VAL_PATH)\n",
    "\n",
    "train_cols = list(train_raw.column_names)\n",
    "val_cols   = list(val_raw.column_names)\n",
    "\n",
    "train_ds = train_raw.map(to_sft_text, remove_columns=train_cols, desc=\"Format train\")\n",
    "val_ds   = val_raw.map(to_sft_text,   remove_columns=val_cols,   desc=\"Format val\")\n",
    "\n",
    "print(\"Example formatted sample:\\n\", train_ds[0][\"text\"][:400] + \" ...\")\n",
    "print(\"Train size:\", len(train_ds), \" Val size:\", len(val_ds))\n",
    "\n",
    "# ====================================\n",
    "# 3) Tokenizer & Model (4-bit QLoRA)\n",
    "# ====================================\n",
    "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=\"float16\")\n",
    "tok = AutoTokenizer.from_pretrained(BASE, use_fast=True, trust_remote_code=True)\n",
    "tok.padding_side = \"left\"; tok.truncation_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE, quantization_config=bnb, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "lora = LoraConfig(\n",
    "    r=32, lora_alpha=32, lora_dropout=0.05, bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    ")\n",
    "\n",
    "# ===========================================\n",
    "# 4) Trainer config + monitoring parameters\n",
    "# ===========================================\n",
    "cfg = SFTConfig(\n",
    "    output_dir=OUT_DIR,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "\n",
    "    logging_steps=5,        # frequent progress prints\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,         # FIXED: More frequent evaluation (was 1000)\n",
    "    save_steps=500,         # save checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    fp16=True, bf16=False,\n",
    "    packing=False,\n",
    "    report_to=[\"tensorboard\"]\n",
    ")\n",
    "\n",
    "tok.model_max_length = 256\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=lora,\n",
    "    args=cfg,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    processing_class=tok,\n",
    "    formatting_func=lambda ex: ex[\"text\"]\n",
    ")\n",
    "\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
    "\n",
    "# ======================================================\n",
    "# 5) Custom monitoring: EM / Format-OK / Abstention-OK\n",
    "# ======================================================\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "def generate_one(model, tok, prompt, max_new_tokens=40):\n",
    "    ids = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**ids, max_new_tokens=max_new_tokens, do_sample=False, temperature=0.0)\n",
    "    text = tok.decode(out[0], skip_special_tokens=True)\n",
    "    return text.split(\"[ASSISTANT]\\n\")[-1].strip().splitlines()[0].strip()\n",
    "\n",
    "def eval_on_slice(model, tok, ds, n=128):\n",
    "    n = min(n, len(ds))\n",
    "    ems, fmt_ok, abst_ok = [], [], []\n",
    "    for i in range(n):\n",
    "        full = ds[i][\"text\"]\n",
    "        prompt, gold = full.split(\"[ASSISTANT]\\n\", 1)\n",
    "        prompt = prompt + \"[ASSISTANT]\\n\"\n",
    "        gold = gold.strip().splitlines()[0].strip()\n",
    "        pred = generate_one(model, tok, prompt)\n",
    "        ems.append(pred == gold)\n",
    "        fmt_ok.append(is_iso_ok(pred))\n",
    "        abstain_req = (gold == \"ABSTAIN\")\n",
    "        abst_ok.append((abstain_req and pred == \"ABSTAIN\") or (not abstain_req))\n",
    "    return {\"em\": sum(ems)/n, \"format_ok\": sum(fmt_ok)/n, \"abstain_ok\": sum(abst_ok)/n, \"n\": n}\n",
    "\n",
    "class DomainEvalCallback(TrainerCallback):\n",
    "    def __init__(self, tok, ds_slice, out_csv):\n",
    "        self.tok = tok\n",
    "        self.ds_slice = ds_slice\n",
    "        self.out_csv = out_csv\n",
    "        self.buffer = []\n",
    "        # FIXED: Initialize CSV file with headers\n",
    "        pd.DataFrame(columns=[\"step\", \"time\", \"em\", \"format_ok\", \"abstain_ok\", \"n\"]).to_csv(out_csv, index=False)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        metrics = eval_on_slice(model, self.tok, self.ds_slice, n=len(self.ds_slice))\n",
    "        row = dict(step=int(state.global_step), time=time.time(), **metrics)\n",
    "        self.buffer.append(row)\n",
    "        pd.DataFrame(self.buffer).to_csv(self.out_csv, index=False)\n",
    "        print(f\"[domain] step={row['step']} EM={row['em']:.3f} fmt={row['format_ok']:.3f} abst={row['abstain_ok']:.3f}\")\n",
    "\n",
    "    # FIXED: Add training end callback to ensure we always have some data\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        if not self.buffer:  # If no evaluations happened during training\n",
    "            print(\"[domain] No evaluations during training, running final evaluation...\")\n",
    "            model = kwargs[\"model\"]\n",
    "            metrics = eval_on_slice(model, self.tok, self.ds_slice, n=min(64, len(self.ds_slice)))\n",
    "            row = dict(step=int(state.global_step), time=time.time(), **metrics)\n",
    "            self.buffer.append(row)\n",
    "            pd.DataFrame(self.buffer).to_csv(self.out_csv, index=False)\n",
    "            print(f\"[domain] final: EM={row['em']:.3f} fmt={row['format_ok']:.3f} abst={row['abstain_ok']:.3f}\")\n",
    "\n",
    "dom_csv = f\"{OUT_DIR}/domain_metrics.csv\"\n",
    "val_slice = val_ds.select(range(min(256, len(val_ds))))\n",
    "trainer.add_callback(DomainEvalCallback(tok, val_slice, dom_csv))\n",
    "trainer.add_callback(TimeLimitCallback(limit_seconds=42900, save_dir=OUT_DIR, tokenizer=tok))\n",
    "\n",
    "# ======================\n",
    "# 6) Train (SFT QLoRA)\n",
    "# ======================\n",
    "trainer.train()\n",
    "\n",
    "# Save adapters & tokenizer\n",
    "trainer.model.save_pretrained(OUT_DIR)\n",
    "tok.save_pretrained(OUT_DIR)\n",
    "print(\"Saved model/adapter to:\", OUT_DIR)\n",
    "\n",
    "# ==============================\n",
    "# 7) Plot & save monitoring figs\n",
    "# ==============================\n",
    "def plot_domain_curves(csv_path, out_dir):\n",
    "    # FIXED: Check if file exists before trying to read it\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Warning: {csv_path} does not exist. Creating empty plots.\")\n",
    "        # Create empty plots as placeholders\n",
    "        for metric, title in [(\"em\", \"Exact-Match\"), (\"format_ok\", \"Format Compliance\"), (\"abstain_ok\", \"Abstention Compliance\")]:\n",
    "            plt.figure(figsize=(7.5,4.5))\n",
    "            plt.text(0.5, 0.5, f\"No data available\\n({csv_path} not found)\", \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.xlabel(\"Global Step\"); plt.ylabel(title)\n",
    "            plt.title(f\"{title} over training\"); plt.grid(True, linewidth=0.4)\n",
    "            plt.tight_layout()\n",
    "            p = f\"{out_dir}/{metric}_curve.png\"\n",
    "            plt.savefig(p, dpi=160)\n",
    "            print(\"Saved placeholder:\", p)\n",
    "            plt.close()\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty:\n",
    "        print(\"domain_metrics.csv is empty; creating placeholder plots.\")\n",
    "        # Same placeholder logic as above\n",
    "        for metric, title in [(\"em\", \"Exact-Match\"), (\"format_ok\", \"Format Compliance\"), (\"abstain_ok\", \"Abstention Compliance\")]:\n",
    "            plt.figure(figsize=(7.5,4.5))\n",
    "            plt.text(0.5, 0.5, \"No evaluation data available\", \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.xlabel(\"Global Step\"); plt.ylabel(title)\n",
    "            plt.title(f\"{title} over training\"); plt.grid(True, linewidth=0.4)\n",
    "            plt.tight_layout()\n",
    "            p = f\"{out_dir}/{metric}_curve.png\"\n",
    "            plt.savefig(p, dpi=160)\n",
    "            print(\"Saved placeholder:\", p)\n",
    "            plt.close()\n",
    "        return\n",
    "    \n",
    "    # EM\n",
    "    plt.figure(figsize=(7.5,4.5))\n",
    "    plt.plot(df[\"step\"], df[\"em\"], marker=\"o\")\n",
    "    plt.xlabel(\"Global Step\"); plt.ylabel(\"Exact-Match\")\n",
    "    plt.title(\"Exact-Match over training\"); plt.grid(True, linewidth=0.4)\n",
    "    plt.tight_layout()\n",
    "    p1 = f\"{out_dir}/em_curve.png\"; plt.savefig(p1, dpi=160); print(\"Saved:\", p1)\n",
    "    plt.close()\n",
    "\n",
    "    # Format OK\n",
    "    plt.figure(figsize=(7.5,4.5))\n",
    "    plt.plot(df[\"step\"], df[\"format_ok\"], marker=\"o\")\n",
    "    plt.xlabel(\"Global Step\"); plt.ylabel(\"Format OK Rate\")\n",
    "    plt.title(\"Format Compliance over training\"); plt.grid(True, linewidth=0.4)\n",
    "    plt.tight_layout()\n",
    "    p2 = f\"{out_dir}/format_ok_curve.png\"; plt.savefig(p2, dpi=160); print(\"Saved:\", p2)\n",
    "    plt.close()\n",
    "\n",
    "    # Abstention OK\n",
    "    plt.figure(figsize=(7.5,4.5))\n",
    "    plt.plot(df[\"step\"], df[\"abstain_ok\"], marker=\"o\")\n",
    "    plt.xlabel(\"Global Step\"); plt.ylabel(\"Abstention Compliance\")\n",
    "    plt.title(\"Abstention Compliance over training\"); plt.grid(True, linewidth=0.4)\n",
    "    plt.tight_layout()\n",
    "    p3 = f\"{out_dir}/abstain_ok_curve.png\"; plt.savefig(p3, dpi=160); print(\"Saved:\", p3)\n",
    "    plt.close()\n",
    "\n",
    "plot_domain_curves(dom_csv, OUT_DIR)\n",
    "\n",
    "# ===============================\n",
    "# 8) TensorBoard (optional)\n",
    "# ===============================\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir \"$OUT_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
